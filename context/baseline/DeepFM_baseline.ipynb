{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B5CiikKdHcQ"
      },
      "source": [
        "# DeepFM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rSLmkhCdHcR"
      },
      "source": [
        "# Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0-HAIZoIdHcS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1376195/3928242427.py:4: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n",
            "/opt/conda/envs/py10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# 주어진 결과와 정확히 비교하기 위한 random seed 고정\n",
        "###############################################################################\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing\n",
        "0. Dataset 다운로드  \n",
        "<br/>\n",
        "1. Rating df 생성  \n",
        "rating 데이터(train_ratings.csv)를 불러와 [user, item, rating]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "2. Genre df 생성   \n",
        "genre 정보가 담긴 데이터(genres.tsv)를 불러와 genre이름을 id로 변경하고, [item, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.    \n",
        "<br/>\n",
        "3. Negative instances 생성   \n",
        "rating 데이터는 implicit feedback data(rating :0/1)로, positive instances로 구성되어 있습니다. 따라서 rating이 없는 item중 negative instances를 뽑아서 데이터에 추가하게 됩니다.   \n",
        "<br/>\n",
        "4. Join dfs   \n",
        "rating df와 genre df를 join하여 [user, item, rating, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "5. zero-based index로 mapping   \n",
        "Embedding을 위해서 user,item,genre를 zero-based index로 mapping합니다.\n",
        "    - user : 0-31359\n",
        "    - item : 0-6806\n",
        "    - genre : 0-17  \n",
        "<br/>\n",
        "6. feature matrix X, label tensor y 생성   \n",
        "[user, item, genre] 3개의 field로 구성된 feature matrix를 생성합니다.   \n",
        "<br/>\n",
        "7. data loader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw rating df\n",
            "           user   item  rating\n",
            "0            11   4643     1.0\n",
            "1            11    170     1.0\n",
            "2            11    531     1.0\n",
            "3            11    616     1.0\n",
            "4            11   2140     1.0\n",
            "...         ...    ...     ...\n",
            "5154466  138493  44022     1.0\n",
            "5154467  138493   4958     1.0\n",
            "5154468  138493  68319     1.0\n",
            "5154469  138493  40819     1.0\n",
            "5154470  138493  27311     1.0\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "Raw genre df - changed to id\n",
            "         item  genre\n",
            "0         318      7\n",
            "2        2571     16\n",
            "5        2959     16\n",
            "9         296      3\n",
            "13        356      3\n",
            "...       ...    ...\n",
            "15925   73106      3\n",
            "15926  109850     16\n",
            "15929    8605     16\n",
            "15931    3689      3\n",
            "15932    8130      5\n",
            "\n",
            "[6807 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# 1. Rating df 생성\n",
        "rating_data = \"../../data/train/train_ratings.csv\"\n",
        "\n",
        "raw_rating_df = pd.read_csv(rating_data)\n",
        "raw_rating_df\n",
        "raw_rating_df['rating'] = 1.0 # implicit feedback\n",
        "raw_rating_df.drop(['time'],axis=1,inplace=True)\n",
        "print(\"Raw rating df\")\n",
        "print(raw_rating_df)\n",
        "\n",
        "users = set(raw_rating_df.loc[:, 'user'])\n",
        "items = set(raw_rating_df.loc[:, 'item'])\n",
        "\n",
        "#2. Genre df 생성\n",
        "genre_data = \"../../data/train/genres.tsv\"\n",
        "\n",
        "raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n",
        "raw_genre_df = raw_genre_df.drop_duplicates(subset=['item']) #item별 하나의 장르만 남도록 drop\n",
        "# print(raw_genre_df)\n",
        "\n",
        "genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n",
        "raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n",
        "print(\"Raw genre df - changed to id\")\n",
        "print(raw_genre_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create Nagetive instances\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31360/31360 [06:43<00:00, 77.73it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joined rating df\n",
            "           user  item  rating  genre\n",
            "0            11  4643     1.0     16\n",
            "1            11   170     1.0     16\n",
            "2            11   531     1.0      1\n",
            "3            11   616     1.0      9\n",
            "4            11  2140     1.0      4\n",
            "...         ...   ...     ...    ...\n",
            "6722466  138493  7086     0.0      3\n",
            "6722467  138493  6731     0.0     17\n",
            "6722468  138493  2713     0.0     17\n",
            "6722469  138493  2072     0.0      3\n",
            "6722470  138493  1889     0.0     14\n",
            "\n",
            "[6722471 rows x 4 columns]\n",
            "Data\n",
            "          user  item  rating  genre\n",
            "0            0  3727     0.0      3\n",
            "1            0  2812     1.0     16\n",
            "2            0  3989     1.0     16\n",
            "3            0   353     1.0     16\n",
            "4            0   687     1.0     16\n",
            "...        ...   ...     ...    ...\n",
            "6722466  31359  2511     0.0     14\n",
            "6722467  31359  2314     0.0      3\n",
            "6722468  31359  6742     0.0     17\n",
            "6722469  31359  5205     0.0     14\n",
            "6722470  31359  3717     0.0      3\n",
            "\n",
            "[6722471 rows x 4 columns]\n",
            "# of data : 6722471\n",
            "# of users : 31360\n",
            "# of items : 6807\n",
            "# of genres : 18\n"
          ]
        }
      ],
      "source": [
        "# 3. Negative instance 생성\n",
        "\n",
        "# 시청횟수를 기준으로 raw_genre_df를 오름차순으로 정렬하고, 시청횟수가 적은 500개 아이템을 선택합니다.\n",
        "# items_few_views = set(raw_genre_df.sort_values(by='views')['item'].head(500))\n",
        "\n",
        "print(\"Create Nagetive instances\")\n",
        "num_negative = 50\n",
        "user_group_dfs = list(raw_rating_df.groupby('user')['item'])\n",
        "first_row = True\n",
        "user_neg_dfs = pd.DataFrame()\n",
        "\n",
        "for u, u_items in tqdm(user_group_dfs):\n",
        "    u_items = set(u_items)\n",
        "    i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n",
        "    \n",
        "    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n",
        "    if first_row == True:\n",
        "        user_neg_dfs = i_user_neg_df\n",
        "        first_row = False\n",
        "    else:\n",
        "        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
        "\n",
        "raw_rating_df = pd.concat([raw_rating_df, user_neg_dfs], axis = 0, sort=False)\n",
        "\n",
        "# 4. Join inter_df, genre_df dfs\n",
        "joined_rating_df = pd.merge(raw_rating_df, raw_genre_df, left_on='item', right_on='item', how='inner')\n",
        "print(\"Joined rating df\")\n",
        "print(joined_rating_df)\n",
        "\n",
        "# 5. Embedding을 위해서 user,item,genre를 zero-based index로 mapping(Zero-based Indexing)\n",
        "#     - Zero-based Indexing :  item 을 0부터 시작하는 인덱스 데이터에 대한 순서 정보로 처리 지만, 여기서는 단순 레이블 인코딩\n",
        "#     - user : 0-31359 / 31360 명\n",
        "#     - item : 0-6806  / 6807 영화 수 / 최대값 68319 있음\n",
        "#     - genre : 0-17   / 18 장르 수\n",
        "users = list(set(joined_rating_df.loc[:,'user']))\n",
        "users.sort()\n",
        "items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "items.sort()\n",
        "genres =  list(set((joined_rating_df.loc[:, 'genre'])))\n",
        "genres.sort()\n",
        "\n",
        "# user 인덱싱\n",
        "if len(users)-1 != max(users):\n",
        "    users_dict = {users[i]: i for i in range(len(users))}\n",
        "    joined_rating_df['user']  = joined_rating_df['user'].map(lambda x : users_dict[x])\n",
        "    users = list(set(joined_rating_df.loc[:,'user']))\n",
        "# item 인덱싱    \n",
        "if len(items)-1 != max(items):\n",
        "    items_dict = {items[i]: i for i in range(len(items))}\n",
        "    joined_rating_df['item']  = joined_rating_df['item'].map(lambda x : items_dict[x])\n",
        "    items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "\n",
        "joined_rating_df = joined_rating_df.sort_values(by=['user'])\n",
        "joined_rating_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data = joined_rating_df\n",
        "print(\"Data\")\n",
        "print(data)\n",
        "\n",
        "n_data = len(data)\n",
        "n_user = len(users)\n",
        "n_item = len(items)\n",
        "n_genre = len(genres)\n",
        "\n",
        "print(\"# of data : {}\\n# of users : {}\\n# of items : {}\\n# of genres : {}\".format(n_data, n_user, n_item, n_genre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3727</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2812</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3989</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>353</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>687</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722466</th>\n",
              "      <td>31359</td>\n",
              "      <td>2511</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722467</th>\n",
              "      <td>31359</td>\n",
              "      <td>2314</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722468</th>\n",
              "      <td>31359</td>\n",
              "      <td>6742</td>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722469</th>\n",
              "      <td>31359</td>\n",
              "      <td>5205</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722470</th>\n",
              "      <td>31359</td>\n",
              "      <td>3717</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6722471 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user  item  genre  rating\n",
              "0            0  3727      3     0.0\n",
              "1            0  2812     16     1.0\n",
              "2            0  3989     16     1.0\n",
              "3            0   353     16     1.0\n",
              "4            0   687     16     1.0\n",
              "...        ...   ...    ...     ...\n",
              "6722466  31359  2511     14     0.0\n",
              "6722467  31359  2314      3     0.0\n",
              "6722468  31359  6742     17     0.0\n",
              "6722469  31359  5205     14     0.0\n",
              "6722470  31359  3717      3     0.0\n",
              "\n",
              "[6722471 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = joined_rating_df[['user', 'item', 'genre', 'rating']]\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DeepFM Architecture\n",
        "\n",
        "   **1. FM component**  \n",
        "       FM component는 우리가 아는 2-way Factorization machines(degree=2)입니다.\n",
        "FM은 variables 간의 interaction을 다음과 같이 모델링 합니다.   \n",
        "     **<center> equation (1) </center>**\n",
        "   $$\\hat{y}(x):=w_0 + \\sum_{i=1}^{n}w_ix_i + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j$$   \n",
        "   이때, 세번째 interaction term을 전개하여 다음과 같이 쓸 수 있습니다.(논문 참고)  \n",
        "   구현 코드는 전개된 식을 바탕으로 합니다.   \n",
        "     **<center> equation (2)> </center>**\n",
        "   $$\\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j = \\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{i,f}x_i)^2-\\sum_{i=1}^{n}v_{i,f}^2x_i^2)$$   \n",
        "           \n",
        "\n",
        "\n",
        "   **2. Deep component**  \n",
        "       Deep component는 MLP Layers로 구성되어 있습니다.   \n",
        "       구현 코드는 Input dimension이 30-20-10인 3 layer MLP 구조입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeepFM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n",
        "        super(DeepFM, self).__init__()\n",
        "        total_input_dim = int(sum(input_dims)) # 입력 특성의 차원 n_user + n_movie + n_genre\n",
        "\n",
        "        # Fm component의 constant bias term과 1차 bias term\n",
        "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
        "        self.fc = nn.Embedding(total_input_dim, 1)\n",
        "\n",
        "        self.embedding = nn.Embedding(total_input_dim, embedding_dim)\n",
        "        self.embedding_dim = len(input_dims) * embedding_dim\n",
        "\n",
        "\n",
        "        mlp_layers = [] # mlp hidden layer\n",
        "        for i, dim in enumerate(mlp_dims):\n",
        "            if i==0:\n",
        "                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n",
        "            else:\n",
        "                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim))\n",
        "            mlp_layers.append(nn.ReLU(True))\n",
        "            mlp_layers.append(nn.Dropout(drop_rate))\n",
        "        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n",
        "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
        "\n",
        "    def fm(self, x):\n",
        "        # x : (batch_size, total_num_input)\n",
        "        embed_x = self.embedding(x)\n",
        "\n",
        "        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n",
        "\n",
        "        square_of_sum = torch.sum(embed_x, dim=1) ** 2\n",
        "        sum_of_square = torch.sum(embed_x ** 2, dim=1)\n",
        "        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
        "        return fm_y\n",
        "\n",
        "    def mlp(self, x):\n",
        "        embed_x = self.embedding(x)\n",
        "\n",
        "        inputs = embed_x.view(-1, self.embedding_dim)\n",
        "        mlp_y = self.mlp_layers(inputs)\n",
        "        return mlp_y\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed_x = self.embedding(x)\n",
        "\n",
        "        # fm component\n",
        "        fm_y = self.fm(x).squeeze(1)\n",
        "\n",
        "        # deep component\n",
        "        mlp_y = self.mlp(x).squeeze(1)\n",
        "\n",
        "        # 시그모이드 함수를 사용하여 ctr 1/0 에 대한 확률 값을 출력\n",
        "        y = torch.sigmoid(fm_y + mlp_y)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train, test 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, data_loader, criterion, optimizer, device):\n",
        "    size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Compute prediction and loss\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, y.float())\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "        if batch % 1000 == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * len(X)\n",
        "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "    train_loss /= num_batches\n",
        "    \n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def test(model, data_loader, criterion, device, task='clf'):\n",
        "    num_batches = len(data_loader)\n",
        "    test_loss, y_all, pred_all = 0, list(), list()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += criterion(pred, y.float()).item() / num_batches\n",
        "            y_all.append(y)\n",
        "            pred_all.append(pred)\n",
        "\n",
        "    y_all = torch.cat(y_all).cpu()\n",
        "    pred_all = torch.cat(pred_all).cpu()\n",
        "\n",
        "    if task == 'reg':\n",
        "        err = abs(pred_all - y_all).type(torch.float).mean().item()\n",
        "        print(f\"Test Error: \\n  MAE: {(err):>8f} \\n  Avg loss: {test_loss:>8f}\")\n",
        "    else:\n",
        "        err = roc_auc_score(y_all, torch.sigmoid(pred_all)).item()\n",
        "        print(f\"Test Error: \\n  AUC: {err:>8f} \\n  Avg loss: {test_loss:>8f}\")\n",
        "\n",
        "    return err, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 하이퍼파라미터 설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "######## Hyperparameter ########\n",
        "batch_size = 1024 # 배치 사이즈\n",
        "data_shuffle = True\n",
        "epochs = 5 # epoch 돌릴 횟수\n",
        "learning_rate = 0.01 # 학습이 반영되는 정도를 나타내는 파라미터\n",
        "weight_decay=1e-6 # 정규화를 위한 파라미터\n",
        "\n",
        "input_dims = [n_user, n_item, n_genre]\n",
        "embed_dim = 10\n",
        "mlp_dims=[30, 20, 10]\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_col = torch.tensor(data.loc[:,'user'])\n",
        "item_col = torch.tensor(data.loc[:,'item'])\n",
        "genre_col = torch.tensor(data.loc[:,'genre'])\n",
        "\n",
        "X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n",
        "y = torch.tensor(list(data.loc[:,'rating']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#7. data loader 생성\n",
        "# 훈련 데이터셋은 미니배치 크기가 1024이고, 테스트 데이터셋은 미니배치 크기가 512인 미니배치로 분할\n",
        "# 훈련 데이터는 에폭마다 shuffle, 다양한 미니배치로 모델 훈련. 테스트 데이터는 섞이지 않고 유지\n",
        "\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_tensor = input_tensor.long()\n",
        "        self.target_tensor = target_tensor.long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_tensor[index], self.target_tensor[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_tensor.size(0)\n",
        "\n",
        "\n",
        "dataset = RatingDataset(X, y)\n",
        "train_ratio = 0.9\n",
        "\n",
        "train_size = int(train_ratio * len(data))\n",
        "test_size = len(data) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.608784 [    0/6050223]\n",
            "loss: 0.532734 [1024000/6050223]\n",
            "loss: 0.482594 [2048000/6050223]\n",
            "loss: 0.479662 [3072000/6050223]\n",
            "loss: 0.476179 [4096000/6050223]\n",
            "loss: 0.468375 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.841710 \n",
            "  Avg loss: 0.474394\n",
            "-------------------------------\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.475679 [    0/6050223]\n",
            "loss: 0.463771 [1024000/6050223]\n",
            "loss: 0.463805 [2048000/6050223]\n",
            "loss: 0.460049 [3072000/6050223]\n",
            "loss: 0.471065 [4096000/6050223]\n",
            "loss: 0.470366 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.850356 \n",
            "  Avg loss: 0.471963\n",
            "-------------------------------\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.469411 [    0/6050223]\n",
            "loss: 0.474396 [1024000/6050223]\n",
            "loss: 0.456533 [2048000/6050223]\n",
            "loss: 0.472388 [3072000/6050223]\n",
            "loss: 0.464269 [4096000/6050223]\n",
            "loss: 0.452049 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.852730 \n",
            "  Avg loss: 0.470815\n",
            "-------------------------------\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.445628 [    0/6050223]\n",
            "loss: 0.471575 [1024000/6050223]\n",
            "loss: 0.483368 [2048000/6050223]\n",
            "loss: 0.475896 [3072000/6050223]\n",
            "loss: 0.456534 [4096000/6050223]\n",
            "loss: 0.480057 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.857452 \n",
            "  Avg loss: 0.469119\n",
            "-------------------------------\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.477953 [    0/6050223]\n",
            "loss: 0.475405 [1024000/6050223]\n",
            "loss: 0.468768 [2048000/6050223]\n",
            "loss: 0.465619 [3072000/6050223]\n",
            "loss: 0.471795 [4096000/6050223]\n",
            "loss: 0.458713 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.851707 \n",
            "  Avg loss: 0.468815\n",
            "-------------------------------\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "model = DeepFM(input_dims, embed_dim, mlp_dims, drop_rate=0.01).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, amsgrad=True, weight_decay=weight_decay)\n",
        "\n",
        "train_loss, test_err, test_loss = list(), list(), list()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss.append(train(model, train_loader, criterion, optimizer, device))\n",
        "    test_result = test(model, test_loader, criterion, device)\n",
        "    test_err.append(test_result[0])\n",
        "    test_loss.append(test_result[1])\n",
        "    print(\"-------------------------------\\n\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Infernece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31360/31360 [02:42<00:00, 193.55it/s]\n"
          ]
        }
      ],
      "source": [
        "# 모든 유저-아이템을 인풋으로 넣어서 결과 생성 후 랭킹 (31360 x 6807)\n",
        "u_list = []\n",
        "i_list = []\n",
        "ritems_dict = {v:k for k,v in items_dict.items()}\n",
        "for u, u_items in tqdm(user_group_dfs):\n",
        "\n",
        "    # 인코딩하기 전에 유저id 저장\n",
        "    u_list.append([u]*10)\n",
        "\n",
        "    # user incoding\n",
        "    u = users_dict[u]\n",
        "    u_items = set(u_items.map(lambda x : items_dict[x])) # incoding된 유저의 시청 아이템\n",
        "\n",
        "    # user, item, genre 데이터를 인코딩하여 학습한 모델에 맞는 값으로 변환\n",
        "    i_user_col = torch.tensor([u] * n_item)\n",
        "    i_item_col = torch.tensor(raw_genre_df['item'].map(lambda x : items_dict[x]).values)\n",
        "    i_genre_col = torch.tensor(raw_genre_df['genre'].values)\n",
        "    \n",
        "    x = torch.cat([i_user_col.unsqueeze(1), i_item_col.unsqueeze(1), i_genre_col.unsqueeze(1)], dim=1)\n",
        "    x = x.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    output_batch = model(x)\n",
        "    output_batch = output_batch.cpu().detach().numpy()\n",
        "\n",
        "    output_batch[list(u_items)] = -1    # 이미 본 아이템 제외\n",
        "    result_batch = np.argsort(output_batch)[-10:][::-1] # Top 10 item_id 추출\n",
        "    i_list.append(list(map(lambda x : ritems_dict[x], result_batch)))   # item decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "u_list = np.concatenate(u_list)\n",
        "i_list = np.concatenate(i_list)\n",
        "submit_df = pd.DataFrame(data={'user': u_list, 'item': i_list}, columns=['user', 'item'])\n",
        "submit_df.to_csv(\"DeepFM_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efIPWtEjHJM9"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
