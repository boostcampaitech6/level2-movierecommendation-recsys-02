{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B5CiikKdHcQ"
      },
      "source": [
        "# Factorization Machine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rSLmkhCdHcR"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0-HAIZoIdHcS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1371389/3928242427.py:4: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n",
            "/opt/conda/envs/py10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# 주어진 결과와 정확히 비교하기 위한 random seed 고정\n",
        "###############################################################################\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgCzGVEpdHcT"
      },
      "source": [
        "## Data preprocessing\n",
        "0. Dataset 다운로드  \n",
        "<br/>\n",
        "1. Rating df 생성  \n",
        "rating 데이터(train_ratings.csv)를 불러와 [user, item, rating]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "2. Genre df 생성   \n",
        "genre 정보가 담긴 데이터(genres.tsv)를 불러와 genre이름을 id로 변경하고, [item, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.    \n",
        "<br/>\n",
        "3. Negative instances 생성   \n",
        "rating 데이터는 implicit feedback data(rating :0/1)로, positive instances로 구성되어 있습니다. 따라서 rating이 없는 item중 negative instances를 뽑아서 데이터에 추가하게 됩니다.   \n",
        "<br/>\n",
        "4. Join dfs   \n",
        "rating df와 genre df를 join하여 [user, item, rating, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "5. zero-based index로 mapping   \n",
        "Embedding을 위해서 user,item,genre를 zero-based index로 mapping합니다.\n",
        "    - user : 0-31359\n",
        "    - item : 0-6806\n",
        "    - genre : 0-17  \n",
        "<br/>\n",
        "6. feature matrix X, label tensor y 생성   \n",
        "[user, item, genre] 3개의 field로 구성된 feature matrix를 생성합니다.   \n",
        "<br/>\n",
        "7. data loader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw rating df\n",
            "           user   item  rating\n",
            "0            11   4643     1.0\n",
            "1            11    170     1.0\n",
            "2            11    531     1.0\n",
            "3            11    616     1.0\n",
            "4            11   2140     1.0\n",
            "...         ...    ...     ...\n",
            "5154466  138493  44022     1.0\n",
            "5154467  138493   4958     1.0\n",
            "5154468  138493  68319     1.0\n",
            "5154469  138493  40819     1.0\n",
            "5154470  138493  27311     1.0\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "Raw genre df - changed to id\n",
            "         item  genre\n",
            "0         318     17\n",
            "2        2571      1\n",
            "5        2959      1\n",
            "9         296     15\n",
            "13        356     15\n",
            "...       ...    ...\n",
            "15925   73106     15\n",
            "15926  109850      1\n",
            "15929    8605      1\n",
            "15931    3689     15\n",
            "15932    8130     10\n",
            "\n",
            "[6807 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# 1. Rating df 생성\n",
        "rating_data = \"../../data/train/train_ratings.csv\"\n",
        "\n",
        "raw_rating_df = pd.read_csv(rating_data)\n",
        "raw_rating_df\n",
        "raw_rating_df['rating'] = 1.0 # implicit feedback\n",
        "raw_rating_df.drop(['time'],axis=1,inplace=True)\n",
        "print(\"Raw rating df\")\n",
        "print(raw_rating_df)\n",
        "\n",
        "users = set(raw_rating_df.loc[:, 'user'])\n",
        "items = set(raw_rating_df.loc[:, 'item'])\n",
        "\n",
        "#2. Genre df 생성\n",
        "genre_data = \"../../data/train/genres.tsv\"\n",
        "\n",
        "raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n",
        "raw_genre_df = raw_genre_df.drop_duplicates(subset=['item']) #item별 하나의 장르만 남도록 drop\n",
        "# print(raw_genre_df)\n",
        "\n",
        "genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n",
        "raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n",
        "print(\"Raw genre df - changed to id\")\n",
        "print(raw_genre_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create Nagetive instances\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31360/31360 [06:44<00:00, 77.59it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joined rating df\n",
            "           user   item  rating  genre\n",
            "0            11   4643     1.0      1\n",
            "1            11    170     1.0      1\n",
            "2            11    531     1.0      7\n",
            "3            11    616     1.0     14\n",
            "4            11   2140     1.0     12\n",
            "...         ...    ...     ...    ...\n",
            "6722466  138493  39715     0.0     15\n",
            "6722467  138493    718     0.0     15\n",
            "6722468  138493   6436     0.0     13\n",
            "6722469  138493   3189     0.0      7\n",
            "6722470  138493   4339     0.0      1\n",
            "\n",
            "[6722471 rows x 4 columns]\n",
            "Data\n",
            "          user  item  rating  genre\n",
            "0            0  5207     0.0      1\n",
            "1            0  2812     1.0      1\n",
            "2            0  3989     1.0      1\n",
            "3            0   353     1.0      1\n",
            "4            0   687     1.0      1\n",
            "...        ...   ...     ...    ...\n",
            "6722466  31359  5217     0.0      1\n",
            "6722467  31359   784     0.0      1\n",
            "6722468  31359  6516     0.0     15\n",
            "6722469  31359  6467     0.0     17\n",
            "6722470  31359  3123     0.0     15\n",
            "\n",
            "[6722471 rows x 4 columns]\n",
            "# of data : 6722471\n",
            "# of users : 31360\n",
            "# of items : 6807\n",
            "# of genres : 18\n"
          ]
        }
      ],
      "source": [
        "# 3. Negative instance 생성\n",
        "\n",
        "# 시청횟수를 기준으로 raw_genre_df를 오름차순으로 정렬하고, 시청횟수가 적은 500개 아이템을 선택합니다.\n",
        "# items_few_views = set(raw_genre_df.sort_values(by='views')['item'].head(500))\n",
        "\n",
        "print(\"Create Nagetive instances\")\n",
        "num_negative = 50\n",
        "user_group_dfs = list(raw_rating_df.groupby('user')['item'])\n",
        "first_row = True\n",
        "user_neg_dfs = pd.DataFrame()\n",
        "\n",
        "for u, u_items in tqdm(user_group_dfs):\n",
        "    u_items = set(u_items)\n",
        "    i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n",
        "    \n",
        "    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n",
        "    if first_row == True:\n",
        "        user_neg_dfs = i_user_neg_df\n",
        "        first_row = False\n",
        "    else:\n",
        "        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
        "\n",
        "raw_rating_df = pd.concat([raw_rating_df, user_neg_dfs], axis = 0, sort=False)\n",
        "\n",
        "# 4. Join inter_df, genre_df dfs\n",
        "joined_rating_df = pd.merge(raw_rating_df, raw_genre_df, left_on='item', right_on='item', how='inner')\n",
        "print(\"Joined rating df\")\n",
        "print(joined_rating_df)\n",
        "\n",
        "# 5. Embedding을 위해서 user,item,genre를 zero-based index로 mapping(Zero-based Indexing)\n",
        "#     - Zero-based Indexing :  item 을 0부터 시작하는 인덱스 데이터에 대한 순서 정보로 처리 지만, 여기서는 단순 레이블 인코딩\n",
        "#     - user : 0-31359 / 31360 명\n",
        "#     - item : 0-6806  / 6807 영화 수 / 최대값 68319 있음\n",
        "#     - genre : 0-17   / 18 장르 수\n",
        "users = list(set(joined_rating_df.loc[:,'user']))\n",
        "users.sort()\n",
        "items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "items.sort()\n",
        "genres =  list(set((joined_rating_df.loc[:, 'genre'])))\n",
        "genres.sort()\n",
        "\n",
        "# user 인덱싱\n",
        "if len(users)-1 != max(users):\n",
        "    users_dict = {users[i]: i for i in range(len(users))}\n",
        "    joined_rating_df['user']  = joined_rating_df['user'].map(lambda x : users_dict[x])\n",
        "    users = list(set(joined_rating_df.loc[:,'user']))\n",
        "# item 인덱싱    \n",
        "if len(items)-1 != max(items):\n",
        "    items_dict = {items[i]: i for i in range(len(items))}\n",
        "    joined_rating_df['item']  = joined_rating_df['item'].map(lambda x : items_dict[x])\n",
        "    items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "\n",
        "joined_rating_df = joined_rating_df.sort_values(by=['user'])\n",
        "joined_rating_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data = joined_rating_df\n",
        "print(\"Data\")\n",
        "print(data)\n",
        "\n",
        "n_data = len(data)\n",
        "n_user = len(users)\n",
        "n_item = len(items)\n",
        "n_genre = len(genres)\n",
        "\n",
        "print(\"# of data : {}\\n# of users : {}\\n# of items : {}\\n# of genres : {}\".format(n_data, n_user, n_item, n_genre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5207</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2812</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3989</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>353</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>687</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722466</th>\n",
              "      <td>31359</td>\n",
              "      <td>5217</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722467</th>\n",
              "      <td>31359</td>\n",
              "      <td>784</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722468</th>\n",
              "      <td>31359</td>\n",
              "      <td>6516</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722469</th>\n",
              "      <td>31359</td>\n",
              "      <td>6467</td>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722470</th>\n",
              "      <td>31359</td>\n",
              "      <td>3123</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6722471 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user  item  genre  rating\n",
              "0            0  5207      1     0.0\n",
              "1            0  2812      1     1.0\n",
              "2            0  3989      1     1.0\n",
              "3            0   353      1     1.0\n",
              "4            0   687      1     1.0\n",
              "...        ...   ...    ...     ...\n",
              "6722466  31359  5217      1     0.0\n",
              "6722467  31359   784      1     0.0\n",
              "6722468  31359  6516     15     0.0\n",
              "6722469  31359  6467     17     0.0\n",
              "6722470  31359  3123     15     0.0\n",
              "\n",
              "[6722471 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = joined_rating_df[['user', 'item', 'genre', 'rating']]\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FM Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efIPWtEjHJM9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FMLayer(nn.Module):\n",
        "    def __init__(self, input_dim, factor_dim):\n",
        "        '''\n",
        "        Parameter\n",
        "            input_dim: Input dimension in sparse representation (2652 in MovieLens-100k)\n",
        "            factor_dim: Factorization dimension\n",
        "        '''\n",
        "        super(FMLayer, self).__init__()\n",
        "        self.v = nn.Parameter(\n",
        "            torch.empty(input_dim, factor_dim)  # FILL HERE : Fill in the places `None` #\n",
        "            , requires_grad = True\n",
        "        )\n",
        "\n",
        "    def square(self, x):\n",
        "        return torch.pow(x,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Parameter\n",
        "            x: Float tensor of size \"(batch_size, input_dim)\"\n",
        "        '''\n",
        "        square_of_sum =  self.square(torch.sum(torch.matmul(x, self.v), dim=1)) # FILL HERE : Use `torch.matmul()` and `self.square()` #\n",
        "        sum_of_square =  torch.sum(torch.matmul(self.square(x), self.square(self.v)), dim=1) # FILL HERE : Use `torch.matmul()` and `self.square()` #\n",
        "\n",
        "        return 0.5 * torch.sum(square_of_sum - sum_of_square, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FactorizationMachine(nn.Module):\n",
        "    def __init__(self, input_dim, factor_dim):\n",
        "        '''\n",
        "        Parameter\n",
        "            input_dim: Input dimension in sparse representation (2652 in MovieLens-100k)\n",
        "            factor_dim: Factorization dimension\n",
        "        '''\n",
        "        super(FactorizationMachine, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(input_dim, 1, bias=True) # FILL HERE : Fill in the places `None` #\n",
        "        self.fm = FMLayer(input_dim, factor_dim) # FILL HERE : Fill in the places `None` #\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, FMLayer):\n",
        "                nn.init.normal_(m.v, 0, 0.01)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Parameter\n",
        "            x: Long tensor of size \"(batch_size, input_dim)\"\n",
        "\n",
        "        Return\n",
        "            y: Float tensor of size \"(batch_size)\"\n",
        "        '''\n",
        "        y = self.linear(x).squeeze(1) + self.fm(x) # FILL HERE : Use `self.linear()` and `self.fm()` #\n",
        "        y = torch.sigmoid(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train, test 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, data_loader, criterion, optimizer, device):\n",
        "    size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Compute prediction and loss\n",
        "        X, y = X.to(device).float(), y.to(device).float()\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, y.float())\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "        if batch % 1000 == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * len(X)\n",
        "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "    train_loss /= num_batches\n",
        "    \n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def test(model, data_loader, criterion, device, task='clf'):\n",
        "    num_batches = len(data_loader)\n",
        "    test_loss, y_all, pred_all = 0, list(), list()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            X, y = X.to(device).float(), y.to(device).float()\n",
        "            pred = model(X)\n",
        "            test_loss += criterion(pred, y.float()).item() / num_batches\n",
        "            y_all.append(y)\n",
        "            pred_all.append(pred)\n",
        "\n",
        "    y_all = torch.cat(y_all).cpu()\n",
        "    pred_all = torch.cat(pred_all).cpu()\n",
        "\n",
        "    if task == 'reg':\n",
        "        err = abs(pred_all - y_all).type(torch.float).mean().item()\n",
        "        print(f\"Test Error: \\n  MAE: {(err):>8f} \\n  Avg loss: {test_loss:>8f}\")\n",
        "    else:\n",
        "        err = roc_auc_score(y_all, torch.sigmoid(pred_all)).item()\n",
        "        print(f\"Test Error: \\n  AUC: {err:>8f} \\n  Avg loss: {test_loss:>8f}\")\n",
        "\n",
        "    return err, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 하이퍼파라미터 설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "######## Hyperparameter ########\n",
        "batch_size = 1024 # 배치 사이즈\n",
        "data_shuffle = True\n",
        "embed_dim = 8 # embed feature의 dimension\n",
        "epochs = 5 # epoch 돌릴 횟수\n",
        "learning_rate = 0.01 # 학습이 반영되는 정도를 나타내는 파라미터\n",
        "weight_decay=1e-6 # 정규화를 위한 파라미터\n",
        "input_dim = data.shape[1] - 1\n",
        "factorization_dim = 8\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_col = torch.tensor(data.loc[:,'user'])\n",
        "item_col = torch.tensor(data.loc[:,'item'])\n",
        "genre_col = torch.tensor(data.loc[:,'genre'])\n",
        "\n",
        "X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n",
        "y = torch.tensor(list(data.loc[:,'rating']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P3N75T9GdHcV"
      },
      "outputs": [],
      "source": [
        "#7. data loader 생성\n",
        "# 훈련 데이터셋은 미니배치 크기가 1024이고, 테스트 데이터셋은 미니배치 크기가 512인 미니배치로 분할\n",
        "# 훈련 데이터는 에폭마다 shuffle, 다양한 미니배치로 모델 훈련. 테스트 데이터는 섞이지 않고 유지\n",
        "\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_tensor = input_tensor.long()\n",
        "        self.target_tensor = target_tensor.long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_tensor[index], self.target_tensor[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_tensor.size(0)\n",
        "\n",
        "\n",
        "dataset = RatingDataset(X, y)\n",
        "train_ratio = 0.9\n",
        "\n",
        "train_size = int(train_ratio * len(data))\n",
        "test_size = len(data) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR-AgXXpdHcX"
      },
      "source": [
        "## Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.524199 [    0/6050223]\n",
            "loss: 0.551543 [1024000/6050223]\n",
            "loss: 0.553496 [2048000/6050223]\n",
            "loss: 0.541777 [3072000/6050223]\n",
            "loss: 0.566191 [4096000/6050223]\n",
            "loss: 0.537871 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.500000 \n",
            "  Avg loss: 0.546316\n",
            "-------------------------------\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.537871 [    0/6050223]\n",
            "loss: 0.555449 [1024000/6050223]\n",
            "loss: 0.522246 [2048000/6050223]\n",
            "loss: 0.546660 [3072000/6050223]\n",
            "loss: 0.551543 [4096000/6050223]\n",
            "loss: 0.549590 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.500000 \n",
            "  Avg loss: 0.546316\n",
            "-------------------------------\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.568145 [    0/6050223]\n",
            "loss: 0.553496 [1024000/6050223]\n",
            "loss: 0.549590 [2048000/6050223]\n",
            "loss: 0.558379 [3072000/6050223]\n",
            "loss: 0.537871 [4096000/6050223]\n",
            "loss: 0.534941 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.500000 \n",
            "  Avg loss: 0.546316\n",
            "-------------------------------\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.555449 [    0/6050223]\n",
            "loss: 0.550566 [1024000/6050223]\n",
            "loss: 0.527129 [2048000/6050223]\n",
            "loss: 0.533965 [3072000/6050223]\n",
            "loss: 0.532012 [4096000/6050223]\n",
            "loss: 0.543730 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.500000 \n",
            "  Avg loss: 0.546316\n",
            "-------------------------------\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.560332 [    0/6050223]\n",
            "loss: 0.545684 [1024000/6050223]\n",
            "loss: 0.565215 [2048000/6050223]\n",
            "loss: 0.511504 [3072000/6050223]\n",
            "loss: 0.577910 [4096000/6050223]\n",
            "loss: 0.570098 [5120000/6050223]\n",
            "Test Error: \n",
            "  AUC: 0.500000 \n",
            "  Avg loss: 0.546316\n",
            "-------------------------------\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "model = FactorizationMachine(input_dim, embed_dim).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, amsgrad=True, weight_decay=weight_decay)\n",
        "\n",
        "train_loss, test_err, test_loss = list(), list(), list()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss.append(train(model, train_loader, criterion, optimizer, device))\n",
        "    test_result = test(model, test_loader, criterion, device)\n",
        "    test_err.append(test_result[0])\n",
        "    test_loss.append(test_result[1])\n",
        "    print(\"-------------------------------\\n\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Infernece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31360/31360 [02:42<00:00, 193.55it/s]\n"
          ]
        }
      ],
      "source": [
        "# 모든 유저-아이템을 인풋으로 넣어서 결과 생성 후 랭킹 (31360 x 6807)\n",
        "u_list = []\n",
        "i_list = []\n",
        "ritems_dict = {v:k for k,v in items_dict.items()}\n",
        "for u, u_items in tqdm(user_group_dfs):\n",
        "\n",
        "    # 인코딩하기 전에 유저id 저장\n",
        "    u_list.append([u]*10)\n",
        "\n",
        "    # user incoding\n",
        "    u = users_dict[u]\n",
        "    u_items = set(u_items.map(lambda x : items_dict[x])) # incoding된 유저의 시청 아이템\n",
        "\n",
        "    # user, item, genre 데이터를 인코딩하여 학습한 모델에 맞는 값으로 변환\n",
        "    i_user_col = torch.tensor([u] * n_item)\n",
        "    i_item_col = torch.tensor(raw_genre_df['item'].map(lambda x : items_dict[x]).values)\n",
        "    i_genre_col = torch.tensor(raw_genre_df['genre'].values)\n",
        "    \n",
        "    x = torch.cat([i_user_col.unsqueeze(1), i_item_col.unsqueeze(1), i_genre_col.unsqueeze(1)], dim=1)\n",
        "    x = x.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    output_batch = model(x)\n",
        "    output_batch = output_batch.cpu().detach().numpy()\n",
        "\n",
        "    output_batch[list(u_items)] = -1    # 이미 본 아이템 제외\n",
        "    result_batch = np.argsort(output_batch)[-10:][::-1] # Top 10 item_id 추출\n",
        "    i_list.append(list(map(lambda x : ritems_dict[x], result_batch)))   # item decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "u_list = np.concatenate(u_list)\n",
        "i_list = np.concatenate(i_list)\n",
        "submit_df = pd.DataFrame(data={'user': u_list, 'item': i_list}, columns=['user', 'item'])\n",
        "submit_df.to_csv(\"FM_submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
